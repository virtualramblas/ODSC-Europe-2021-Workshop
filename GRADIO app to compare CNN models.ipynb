{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GRADIO app to compare CNN models.ipynb","provenance":[{"file_id":"1yhuSqDhJ5UEVZ-n7WDM-l64JkrshblZl","timestamp":1620912807724},{"file_id":"1LsMyL1ksbeEuWrkbCgWWKCVO9Nenv9nA","timestamp":1594254819280}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pE8Y2yIHqUVd"},"source":["## A Gradio Interface to Compare Diverse CNN Architectures.\n","This notebook is part of Module 3 of the [ODSC Europe 2021](https://odsc.com/europe/) workshop [Adversarial Attacks and Defence in Computer Vision 101](https://odsc.com/speakers/adversarial-attacks-and-defence-in-computer-vision-101/).  \n","![ODSC Logo](https://opendatascience.com/wp-content/uploads/2021/01/odsceutop.png)  \n","It includes a [Gradio](https://github.com/gradio-app/gradio-UI) interface to compare diverse CNN models performance in image classification tasks.  \n","This notebook can be executed in a CPU runtime with good performance. No need to connect it to a GPU or TPU runtime."]},{"cell_type":"markdown","metadata":{"id":"22As8EJ5OKOn"},"source":["Install the Gradio Python package from PyPi."]},{"cell_type":"code","metadata":{"id":"QjEzkm8SkH4Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621721876385,"user_tz":-60,"elapsed":12480,"user":{"displayName":"Guglielmo Iozzia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJHfIbwiblAhhxtPYG4kd2SwxJiAxxM9UUMTOZzA=s64","userId":"16497662354128021783"}},"outputId":"dfd38920-dd09-406e-da65-46e43f1d44a6"},"source":["!pip install -q gradio "],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.1MB 6.9MB/s \n","\u001b[K     |████████████████████████████████| 1.9MB 18.7MB/s \n","\u001b[K     |████████████████████████████████| 215kB 37.3MB/s \n","\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n","\u001b[K     |████████████████████████████████| 962kB 38.5MB/s \n","\u001b[K     |████████████████████████████████| 3.2MB 38.4MB/s \n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Knn-2niyOPZQ"},"source":["Import the necessary dependencies."]},{"cell_type":"code","metadata":{"id":"XF4NHuvXjzXM","executionInfo":{"status":"ok","timestamp":1621721893031,"user_tz":-60,"elapsed":4021,"user":{"displayName":"Guglielmo Iozzia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJHfIbwiblAhhxtPYG4kd2SwxJiAxxM9UUMTOZzA=s64","userId":"16497662354128021783"}}},"source":["import gradio as gr\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import requests"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvMX1rZyOWRK"},"source":["Download the human-readable labels for the ImageNet data set."]},{"cell_type":"code","metadata":{"id":"iyy7y7c-nOWg","executionInfo":{"status":"ok","timestamp":1621721895188,"user_tz":-60,"elapsed":7,"user":{"displayName":"Guglielmo Iozzia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJHfIbwiblAhhxtPYG4kd2SwxJiAxxM9UUMTOZzA=s64","userId":"16497662354128021783"}}},"source":["response = requests.get(\"https://git.io/JJkYN\")\n","labels = response.text.split(\"\\n\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOaBFIJaOnyK"},"source":["Load the models."]},{"cell_type":"code","metadata":{"id":"-eDou472kBS4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621721908841,"user_tz":-60,"elapsed":12161,"user":{"displayName":"Guglielmo Iozzia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJHfIbwiblAhhxtPYG4kd2SwxJiAxxM9UUMTOZzA=s64","userId":"16497662354128021783"}},"outputId":"935d5e48-f0de-49b8-ad65-967a23700370"},"source":["inception_net = tf.keras.applications.InceptionV3(weights='imagenet')\n","efficient_net = tf.keras.applications.EfficientNetB5(weights='imagenet')\n","mobile_net = tf.keras.applications.MobileNetV2(weights='imagenet')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n","96116736/96112376 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5.h5\n","123469824/123465288 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n","14540800/14536120 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k13TVxvHOuBA"},"source":["Define the classification function for each model."]},{"cell_type":"code","metadata":{"id":"miqWx7pmOu8C","executionInfo":{"status":"ok","timestamp":1621721919096,"user_tz":-60,"elapsed":448,"user":{"displayName":"Guglielmo Iozzia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJHfIbwiblAhhxtPYG4kd2SwxJiAxxM9UUMTOZzA=s64","userId":"16497662354128021783"}}},"source":["\n","def classify_image_with_inception_net(im):\n","\tim = Image.fromarray(im.astype('uint8'), 'RGB')\n","\tim = im.resize((299, 299))\n","\tarr = np.array(im).reshape((-1, 299, 299, 3))\n","\tarr = tf.keras.applications.inception_v3.preprocess_input(arr)\n","\tprediction = inception_net.predict(arr).flatten()\n"," \n","\treturn {labels[i]: float(prediction[i]) for i in range(1000)}\n","\n","def classifiy_image_with_efficient_net(im):\n","  im = Image.fromarray(im.astype('uint8'), 'RGB')\n","  im = im.resize((456, 456))\n","  arr = np.array(im).reshape((-1, 456, 456, 3))\n","  arr = tf.keras.applications.efficientnet.preprocess_input(arr)\n","  prediction = efficient_net.predict(arr).flatten()\n","\n","  return {labels[i]: float(prediction[i]) for i in range(1000)}\n","\n","def classify_image_with_mobile_net(im):\n","  im = Image.fromarray(im.astype('uint8'), 'RGB')\n","  im = im.resize((224, 224))\n","  arr = np.array(im).reshape((-1, 224, 224, 3))\t\n","  arr = tf.keras.applications.mobilenet.preprocess_input(arr)\n","  prediction = mobile_net.predict(arr).flatten()\n","  \n","  return {labels[i]: float(prediction[i]) for i in range(1000)}"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p3FQbJlhO41x"},"source":["Build the Gradio interface."]},{"cell_type":"code","metadata":{"id":"OA2TmWTJkC7g","colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"status":"ok","timestamp":1621721929428,"user_tz":-60,"elapsed":3039,"user":{"displayName":"Guglielmo Iozzia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJHfIbwiblAhhxtPYG4kd2SwxJiAxxM9UUMTOZzA=s64","userId":"16497662354128021783"}},"outputId":"90138df8-f02c-420a-ff4b-7d42182b8b7a"},"source":["imagein = gr.inputs.Image()\n","label = gr.outputs.Label(num_top_classes=3)\n","debug = False\n","\n","gr.Interface(\n","    [classify_image_with_inception_net, classifiy_image_with_efficient_net, classify_image_with_mobile_net], \n","    imagein, \n","    label,\n","    title=\"CNN Models Comparison\",\n","    description=\"Let's compare some state-of-the-art machine learning models that classify images into one of 1,000 categories.\"\n",").launch(debug=debug);"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n","This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n","Running on External URL: https://23982.gradio.app\n","Interface loading below...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","        <iframe\n","            width=\"1000\"\n","            height=\"500\"\n","            src=\"https://23982.gradio.app\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7f9f7cf00f50>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Tip: Add interpretation to your model by simply adding `interpretation=\"default\"` to `Interface()`\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VsYULBhZhc0M"},"source":["#### The interface is now live on the gradio.app link shown above. Go ahead and open that in a new tab!"]},{"cell_type":"markdown","metadata":{"id":"xn27MzU0hdS2"},"source":["Please contact us [here](mailto:team@gradio.app) if you have any questions, or [open an issue](https://github.com/gradio-app/gradio-UI/issues/new/choose) at our github repo.\n","\n"]}]}